"""This is the library for our UCD Decision Analytics MCDA project.

These libraries read the relevant data from Google Spreadsheet. Format it into
a data dictionary and then converts the dictionaries ito relevant tree level
matrices.
"""
import json
import gspread
from oauth2client.client import SignedJwtAssertionCredentials
import numpy
import pandas
from collections import namedtuple
import networkx
import matplotlib.pyplot as plt
import scoring

Edge = namedtuple('Edge', ['source', 'target', 'relative_weight'])


def GetDataFromGoogleSpreadsheet(spreadsheet_key):
  """Reads data from the relevant google speadsheet.

  Reads the data into a list of dictionaries. Required the .json pass file.

  Returns:
    A list of dictionaries.
  """
  json_key = json.load(open('MCDA-UCD-8b0b964e491d.json'))
  scope = ['https://spreadsheets.google.com/feeds']
  credentials = SignedJwtAssertionCredentials(
      json_key['client_email'], json_key['private_key'].encode(), scope)
  gc = gspread.authorize(credentials)
  wks = gc.open_by_key(spreadsheet_key).get_worksheet(0)
  cell_list = wks.get_all_records()
  return cell_list


def GetStructuredDataRollup(data):
  """Restructures the spreadsheet data into a nested structure including scores.

  Args:
    data: a Google spreadsheet cell list.
  Returns:
    A list of dictionairies with each dict corresponding to a given spreadsheet
      row. 
  """
  return_list = []
  for data_dict in data:
    map_values = {}
    for key, value in data_dict.iteritems():
      if key != 'Timestamp':
        keyword1, keyword2 = key.replace('\'','').split(' or ')
        print keyword1
        # This is where I assign the default scores between +-3 that are used in
        # the scoring functions for the final matrices.
        map_values[key] = {keyword1: 4-value, keyword2: value-4}
    return_list.append(map_values)
  return return_list


def ConstructQuestionScoringMatrix(question_set, structured_data_dict,
                                   scoring_function=scoring.Linear,
                                   bias=1):
  """Constructs a numerical matrix from the provided question set and data dict.

  Args:
    question_set: A set of string keywords.
    structured_data_dict: A structured data dict generated by
      GetStructuredDataRollup.
    scoring_function: function that maps the base values to the matrix scores.
    bias: The bias term for the matrix.

  Returns:
    A pandas DataFrame object with rows and columns corresponding to the
      questions in the input question set.
  """
  n = len(question_set)
  question_list = sorted([question for question in question_set])

  bias_matrix = (numpy.ones((n, n)) - numpy.identity(n)) * bias
  df = pandas.DataFrame(bias_matrix, index=question_list, columns=question_list)
  for row in structured_data_dict:
    for key, value in row.iteritems():
      # key is the question and value is a dict of keyword to score.
      keyword1, keyword2 = key.replace('\'','').split(' or ')
      # Just need to check the first of the or words
      if keyword1 in question_set:
        df[keyword1][keyword2] += scoring_function(value[keyword2])
        df[keyword2][keyword1] += scoring_function(value[keyword1])
  return df


def NormalizeDataFrame(data_frame):
  """Divides all columns in a DataFrame by the sum of that column.

  Converts column of arbitrary scores to one in which all columns sum to 1.
  Necessary preprocessing before Markov chains.

  Args:
    data_frame: a pandas DataFrame object.

  Returns:
    A pandas DataFrame object with normalized scores.
  """
  new_df = data_frame /data_frame.sum()
  return new_df


def GetMarkovScoresList(question_square_matrix):
  """Takes our score matrix and converts in to a list of final scores.

  Args:
    question_square_matrix: A square question matrix with its respective scores
      as populated by ConstructQuestionScoringMatrix above.

  Returns:
    A list of tuples of typ (string label and numerical score).
  """
  n = len(question_square_matrix)
  if n==2:
    labels = list(question_square_matrix.index)
    tempframe = question_square_matrix/question_square_matrix.sum().sum()
    scores = ( tempframe[labels[1]][0], tempframe[labels[0]][1])
    return zip(labels, scores)
  # TODO(Max) Why Normalize here and seperately?
  NormalizedSquareMatrix = NormalizeDataFrame(question_square_matrix)
  transition_matrix = numpy.linalg.matrix_power(NormalizedSquareMatrix, 1000)
  # Need an n * 1 matrix of 1/n to multiply by the transition matrix
  fractional_score_matrix = numpy.ones((n, 1))*(1/(n*1.0))
  final_score = numpy.dot(transition_matrix, fractional_score_matrix)
  labels = list(NormalizedSquareMatrix.index)
  output = zip(labels, final_score)
  return output


def _GenerateGraphEdges(source_node, markov_score_list):
  """Creates a list of Edge named tuples from a given node with weights.

  Reads the score list and returns a list of Edges.

  Args:
    source_node:
    markov_score_list:

  Returns:
    A list of edges.
  """
  edge_list = []
  for score in markov_score_list:
    edge_list.append(Edge(source_node, score[0], score[1]))
  return edge_list


def GenerateCompleteGraph(
        question_dict, structured_data_dict, scoring_function, bias):
  """Generates all the edges for the given network.

  Args:
    question_dict: A dict mapping questions to question sets.
    structured_data_dict: A data dictionary from GetStructuredDataRollup above.
    scoring_function: function that maps the base values to the matrix scores.
    bias: The bias term for the matrix.

  Returns:
    A list of all the edges in the network.
  """
  edge_list = []
  for key, value in question_dict.iteritems():
    scores = CalculateScores(value, structured_data_dict, scoring_function,
                             bias)
    edge_list.extend(_GenerateGraphEdges(key, scores))
  return edge_list


def CalculateScores(question_set, structured_data_dict,
                    scoring_function=scoring.Linear, bias=1):
  """Calculates scores for a given question set.

  Given the question set, structured data and scoring function this function
  calculates and returns the final scores.

  Args:
    question_set: A set of string questions.
    structured_data_dict: A data dictionary from GetStructuredDataRollup above.
    scoring_function: function that maps the base values to the matrix scores.
    bias: The bias term for the matrix.

    scoring_default: Boolean whether to use default or alternative scoring.

  Returns:
    The final score list.
  """
  dataframe = ConstructQuestionScoringMatrix(question_set, structured_data_dict,
                                             scoring_function, bias)
  print dataframe
  norm_dataframe = NormalizeDataFrame(dataframe)
  print norm_dataframe
  final_scores = GetMarkovScoresList(dataframe)
  print final_scores
  return final_scores


def GenerateNetworkGraph(question_dict, structured_data_dict, scoring_function,
                         bias):
  """Assemble a networkx DiGraph from the provided data.

  Args:
    question_dict: A dictionary mapping questions to question sets.
    structured_data_dict: A data dictionary from GetStructuredDataRollup above.
    scoring_function: function that maps the base values to the matrix scores.
    bias: The bias term for the matrix.

  Returns:
    A networkx edge weighted DiGraph.
  """
  graph = networkx.DiGraph()
  all_edges = GenerateCompleteGraph(
      question_dict, structured_data_dict, scoring_function, bias)
  for edge in all_edges:
    graph.add_edge(edge.source, edge.target, weight=edge.relative_weight)
  return graph


def PlotNetworkGraph(graph):
  """Plots the provided networkx graph.

  Args:
    graph: A networkx graph object.
  """
  font_size = 9
  pos=networkx.graphviz_layout(graph, prog='dot')
  networkx.draw_networkx(graph, pos=pos, ax=None, with_labels=True, font_size=font_size)
  labels = networkx.get_edge_attributes(graph,'weight')
  networkx.draw_networkx_edge_labels(graph, pos, edge_labels=labels,
                                     font_size=font_size)
  plt.draw()
  plt.show()


def GetEndLevelWeights(graph):
  """Crawls entire network from the top to get the end level relative weights.

  Args:
    graph: A networkx Graph object.

  Returns:
    A sorted list of tuples of (Node name, score), sorted by descending score.
  """
  weights_list = []
  _CrawlNetwork(graph,'ROOT', 1.0, weights_list)
  return sorted(weights_list, key=lambda tup: tup[1], reverse=True)


def _CrawlNetwork(graph, node_name, weight, return_tuple_list):
  """Recursively crawl graph to find end nodes and return them and their scores.

  Work from a starting node and check its neighbors. If it has any crawl them.
  If not append the value and weight to the input list. The new  weight is their
  relative weight, calculated by multiplying parent weight by that branch weight.

  Args:
    graph: A networkx Graph object.
    node_name: A string name of the node to crawl from.
    weight: A numeric weight.
    return_tuple_list: The input list is modified in the function call.

  Returns:
    Nothing. Modifies input value return_tuple_list by appending tuples of type 
      (node_name, numeric weight).
  """
  successors = graph.neighbors(node_name)
  if successors:
    for child_node in successors:
      _CrawlNetwork(
          graph, child_node, weight*graph[node_name][child_node]['weight'],
          return_tuple_list)
  else:
    return_tuple_list.append((node_name, weight))
